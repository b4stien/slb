# -*- coding: utf8 -*-
# Extracteur 

"""  
Some explanations about this script :

1. input : 1 Json config file generated by the Configurator. Input is made at line 756.

1. output : 2 CSV files showing the infos we need about those MATs. Output are made at lines 774 and 783 : 
       - Mats.csv : columns = timestamp, takenID, serialNo, testID, status, failLogLink link when it exists
       - Relative_TFLs.csv  : columns = timestamp, takenID, serialNo, testID, remarks, repeat Operations

2. process ( in MAIN, starting line 663 ) :
       1 - We log onto eQuality HomePage with an emulated selenium webbrowser
       2 - We go to the MatsResult Page that matches our input list, using selenium API.
       3 - We parse it and save what we need into Mats.csv.
       4 - We go to the TFLResult Page that sums up the TFLs we found while parsing the MatsResult Page parsing.
       5 - We parse it and save what we need into Relative_TFLs.csv.

3. classes : We implemented 2 classes based on python HTMLParser, adapting it to the MatsResult pages and to the TFLResult pages :
       - MatsParser ( line 60 ):
           Methods : - initTemporaryResultsAndCounters ( self ) : resets current result and counters
                     - feed ( self, html )                      : feeds one page
                     - feedEveryPage ( self, browser )          : feeds all of the MatsResult pages
                     - timeStamp ( self, matsTime )             : converts the Mats Verified Date into a timeStamp
                     - handle_starttag ( self, tag, attrs )     : handles html starttag
                     - handle_endtag ( self, tag )              : handles html endtag
                     - handle_data ( self, data )               : handles data
                     - endOfTr ( self )                         : appends current result to global result
                     - getResultByTakenID ( self )              : gets global result
       - TFLParser ( line 251 ):
           Methods : - initTemporaryResultsAndCounters ( self ) : resets current result and counters
                     - feed ( self, html )                      : feeds one page
                     - feedEveryPage ( self, browser )          : feeds all of the MatsResult pages
                     - timeStamp ( self, matsTime )             : converts the Mats Verified Date into a timeStamp
                     - handle_starttag ( self, tag, attrs )     : handles html starttag
                     - handle_endtag ( self, tag )              : handles html endtag
                     - handle_data ( self, data )               : handles data
                     - endOfTr ( self )                         : appends current result to global result
                     - getResultByTakenID ( self )              : gets global result

"""

from collections import defaultdict
import json
import csv
from HTMLParser import HTMLParser
import datetime
from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support.ui import Select
from selenium.webdriver.common.action_chains import ActionChains
import time
import os


"""""""""""""""""""""""""""      CLASSES      """""""""""""""""""""""""""


""" MatsParser definition, to create a controller that will help us to parse a MatsResult Page """
class MatsParser(HTMLParser):
    
    def __init__(self, dbTakenID= [] ):
        HTMLParser.__init__(self)

        self.table = False
        self.tr = False
        self.td = False
        self.b = False
        self.a = False

        self.resultsByTakenID = dbTakenID
        self.initTemporaryResultsAndCounters()

        self.takenIDCol = 0
        self.modifiedDateCol = 29
        self.serialNoCol = 24
        self.testIDCol = 1
        self.statusCol = 6
        self.failLogLinkCol = 34

        self.listCol = [ self.modifiedDateCol, self.takenIDCol, self.serialNoCol, \
                    self.testIDCol, self.statusCol, self.failLogLinkCol]

        self.lengthResultCol = 35
    
    def initTemporaryResultsAndCounters(self):
        """ result is the temporary 'one row' result. It's appended to resultsByTakenID (which is the real result)
        and then deleted in endOfTR, called at the end of each html table row """
        self.result = ['']* 6 
        self.pagesNb = 0
        self.currentPageNo = 0
        self.pageRowStart = 0
        self.pageRowEnd = 0
        self.resultsNb = 0

        """ counters """
        self.tablei = 0 
        self.tdi = 0 
        self.bi = 0 
        self.tri = 0 

    """ feeds one html page """
    def feed(self, html):
        self.initTemporaryResultsAndCounters()
        HTMLParser.feed(self, html)
        # In order to check that we have parsed new values (from a new page).
        return self.pageRowStart

    """ if several, feeds all of the MatsResult pages """
    def feedEveryPage(self, browser):
        pageWebSource = browser.page_source.encode('utf8')        
        rowStart = self.feed(pageWebSource) 
        # Go to the next pages if any.
        pageNbTotal = self.pagesNb
        if pageNbTotal > 1:
            newRowStart = rowStart # In order to check that we parse new results.
            i = 2 # Page 1 is already parsed.
            while i <= pageNbTotal:
                while newRowStart == rowStart:
                    link = browser.find_elements_by_link_text(str(i))                
                    if len(link) == 0:
                        # Try to find a "More pages" link.
                        # eQ displays page links by group of 10 only.
                        link = browser.find_elements_by_link_text("More->>")[0]
                    else:
                        link = link[0].find_elements_by_tag_name('font')[0]

                    # Before any mouse action, re-focus on the window in case the
                    # user has clicked away.
                    browser.switch_to_active_element()
                    link.click()
                    newRowStart = self.feed(browser.page_source.encode('utf8'))                    
                rowStart = newRowStart
                i += 1

    """turns the Mats Verified Date into a timestamp"""
    def timeStamp (self, matsTime):

        thisMatsDateTime = datetime.datetime.strptime(matsTime, \
                                                     '%d-%b-%Y %I:%M %p')
        epoch = datetime.datetime.utcfromtimestamp(0)
        delta = thisMatsDateTime - epoch
        thisMatsTimeStamp = int(delta.total_seconds())
        return str(thisMatsTimeStamp)

    def handle_starttag(self, tag, attrs):
        """ tables counter is incremented at start tag """ 
        if tag == 'table':
            self.table = True
            self.tablei += 1
            
        """ rows and cells counters will be at end tag """
        if tag == 'tr' and self.table:
            self.tr = True

        elif tag == 'td' and self.tr:
            self.td = True
        
        elif (tag == 'b' or tag == 'strong') and self.td:
            """bold tags also need to be counted, especially for the feedEveryPage method """
            self.b = True
            self.bi += 1
            
        elif (tag == 'a') and self.td and self.tdi == self.failLogLinkCol:
            """ in case of link to a TFL in the row, adds 'true' at the right position of result """
            for name, value in attrs :
                if name == "href" :
                    self.result[self.listCol.index(self.failLogLinkCol)] = value
            
    def handle_endtag(self, tag):
        
        if tag == 'table':
            self.table = False
            self.tr = False
            self.td = False
            self.b = False

            self.tri = 0

            """ incrementation of rows and cells counters, as promised """
        elif tag == 'tr':
            self.tr = False
            self.td = False
            self.b = False

            self.tri += 1

            self.endOfTr()

            """ Re-initialization of cells counter and temporary result."""
            self.tdi = 0
            self.result = [''] * 6
        
        elif tag == 'td':
            self.td = False
            self.b = False


            self.tdi += 1 
            self.bi = 0 

        elif tag == 'b' or tag == 'strong':
            self.b = False

    def handle_data(self, data):
        """ Table 1 contains infos about the current page and the total number
        of pages to parse, valuable for the feedEveryPage method """
        if self.tablei == 1 and self.b:
            if self.bi == 3:
                self.pagesNb = int(data)
                if self.pagesNb == 1:
                    self.bi += 1 # only 1 page => no page link (in which there would else be one bold balise) 
                    self.currentPageNo = 1
            elif self.bi == 4 and self.pagesNb > 1:
                self.currentPageNo = int(data)
            elif self.bi == 5:
                self.pageRowStart = int(data.lstrip('Rows '))
            elif self.bi == 6:
                self.pageRowEnd = int(data)

            """table 2 contains infos about the total number of rows to parse """
        elif self.tablei == 2 and self.b:
            self.resultsNb = int(data)

            """table 3 contains the actual datas that we want """
        elif self.tablei == 3 :
            """ we check wether we are in one of the interesting columns. If we do, we store the datas in result"""
            if self.tdi < self.lengthResultCol and self.td and self.tdi in self.listCol:
                indexCol = self.listCol.index(self.tdi)
                if self.tdi != self.failLogLinkCol:   
                    if self.result[indexCol] == '':
                        self.result[indexCol] = data.replace("\xc2\xa0", " ")
                    else:
                        self.result[indexCol] += ' ' + data.replace("\xc2\xa0", " ")        

    """ called at the end of each html table row, endOfTr appends the current result to resultsByTakenID """            
    def endOfTr(self):
        if self.tablei == 3 and self.tdi == self.lengthResultCol :            
            r = self.result            
            # transform matsTime to matsTimeStamp
            r[self.listCol.index(self.modifiedDateCol)] = self.timeStamp(r[self.listCol.index(self.modifiedDateCol)])            
            self.resultsByTakenID.append(r)

    """ gets the global result : the list of lists showing the datas we need """
    def getResultByTakenID(self):
        return self.resultsByTakenID



""" TFLParser definition, to create a controller that will help us to parse a MatsResult Page """
class TFLParser(HTMLParser):
    
    def __init__(self, dbTakenID= [] ):
        HTMLParser.__init__(self)

        self.table = False
        self.tr = False
        self.td = False
        self.b = False
        self.a = False

        self.resultsByTakenID = dbTakenID
        self.initTemporaryResultsAndCounters()

        self.takenIDCol = 0
        self.testIDCol = 1
        self.DateCol = 3        
        self.RemarksCol = 17
        self.RepeatOperationsCol = 21
        self.serialNumberCol = 29

        self.listCol = [ self.DateCol, self.takenIDCol, self.serialNumberCol, self.testIDCol, self.RemarksCol, self.RepeatOperationsCol]

        self.lengthResultCol = 39

    def initTemporaryResultsAndCounters(self):
        """ result is the temporary 'one row' result. It's appended to resultsByTakenID (which is the real result)
        and then deleted in endOfTR, called at the end of each html table row """
        self.result = ['']* 6 
        self.pagesNb = 0
        self.currentPageNo = 0
        self.pageRowStart = 0
        self.pageRowEnd = 0
        self.resultsNb = 0

        """counters"""
        self.tablei = 0
        self.tdi = 0 
        self.bi = 0 
        self.tri = 0     

    """ feeds one html page """
    def feed(self, html):
        self.initTemporaryResultsAndCounters()
        HTMLParser.feed(self, html)
        # In order to check that we have parsed new values (from a new page).
        return self.pageRowStart

    """ if several, feeds all of the MatsResult pages """
    def feedEveryPage(self, browser):

        pageWebSource = browser.page_source.encode('utf8')
        
        # parser.feed return pageRowStart(type int)
        rowStart = self.feed(pageWebSource) 

        # Go to the next pages if any.
        pageNbTotal = self.pagesNb
        if pageNbTotal > 1:
            newRowStart = rowStart 
            i = 2 # Page 1 is already parsed.
            while i <= pageNbTotal:
                while newRowStart == rowStart:
                    link = browser.find_elements_by_link_text(str(i)) 
                    if len(link) == 0:
                        # Try to find a "More pages" link.
                        # eQ displays page links by group of 10 only.
                        link = browser.find_elements_by_link_text("More->>")[0]
                    else:
                        link = link[0].find_elements_by_tag_name('font')[0]

                    # Before any mouse action, re-focus on the window in case the
                    # user has clicked away.
                    browser.switch_to_active_element()
                    link.click()
                    newRowStart = self.feed(browser.page_source.encode('utf8'))
                rowStart = newRowStart
                i += 1
                
    """turns the TFL Date into a timestamp"""
    def timeStamp (self, TFLDate):

        thisTFLDate = datetime.datetime.strptime(TFLDate, \
                                                     '%d-%b-%Y')

        epoch = datetime.datetime.utcfromtimestamp(0)
        delta = thisTFLDate - epoch
        thisTFLTimeStamp = int(delta.total_seconds())
        return str(thisTFLTimeStamp)
    
    def handle_starttag(self, tag, attrs):
        """ tables counter is incremented at start tag """ 
        if tag == 'table':
            self.table = True
            self.tablei += 1 
            
            """ rows and cells counters will be at end tag """
        if tag == 'tr' and self.table:
            self.tr = True
        
        elif tag == 'td' and self.tr:
            self.td = True
            
            """bold tags also need to be counted, especially for the feedEveryPage method """
        elif (tag == 'b' or tag == 'strong') and self.td:
            self.b = True
            self.bi += 1        

    def handle_endtag(self, tag):
        
        if tag == 'table':
            self.table = False
            self.tr = False
            self.td = False
            self.b = False

            self.tri = 0
            
            """ incrementation of rows and cells counters, as promised """
        elif tag == 'tr':
            self.tr = False
            self.td = False
            self.b = False

            self.tri += 1

            self.endOfTr()

            """ Re-initialization of cells counter and temporary result."""
            self.tdi = 0
            self.result = [''] * 6
        
        elif tag == 'td':
            self.td = False
            self.b = False

            self.tdi += 1 
            self.bi = 0 

        elif tag == 'b' or tag == 'strong':
            self.b = False

    def handle_data(self, data):
        """ Table 1 contains infos about the current page and the total number
        of pages to parse, valuable for the feedEveryPage method """
        if self.tablei == 1 and self.b:
            if self.bi == 3:
                self.pagesNb = int(data)
                if self.pagesNb == 1:
                    self.bi += 1 # only 1 page => no page link (in which there would else be one bold balise) 
                    self.currentPageNo = 1
            elif self.bi == 4 and self.pagesNb > 1:
                self.currentPageNo = int(data)
            elif self.bi == 5:
                self.pageRowStart = int(data.lstrip('Rows '))
            elif self.bi == 6:
                self.pageRowEnd = int(data)

            """table 2 contains infos about the total number of rows to parse """
        elif self.tablei == 2 and self.b:
            self.resultsNb = int(data)

            """table 3 contains the actual datas that we want """
        elif self.tablei == 3 :
            """ we check wether we are in one of the interesting columns. If we do, we store the datas in result"""
            if self.tdi < self.lengthResultCol and self.td and self.tdi in self.listCol:
                indexCol = self.listCol.index(self.tdi)
                if self.result[indexCol] == '':
                    self.result[indexCol] = data.replace("\xc2\xa0", " ").replace("\n", " ")
                else:
                    self.result[indexCol] += ' ' + data.replace("\xc2\xa0", " ").replace("\n", " ")
                    
    """ called at the end of each html table row, endOfTr appends the current result to resultsByTakenID """                        
    def endOfTr(self):
        # If we have found all cells (td), then transfer temporary result
        # into classified result.
        if self.tablei == 3 and self.tdi == self.lengthResultCol :            
            r = self.result
            # transforming matsTime to matsTimeStamp
            r[self.listCol.index(self.DateCol)] = self.timeStamp(r[self.listCol.index(self.DateCol)])
            
            self.resultsByTakenID.append(r)

    """ gets the global result : the list of lists showing the datas we need """
    def getResultByTakenID(self):
        return self.resultsByTakenID



"""""""""""""""""""""""""""      CONVENIENCE FUNCTIONS     """""""""""""""""""""""""""


""" writes a list into a csv file in current directory """
def listToCsv ( csvFileName, listName):
    with open(csvFileName, 'wb') as f:
        writer = csv.writer(f, delimiter=',')
        writer.writerows(listName)


""" generates a list of the takenIDs for which there has been a TFL
    from the MatsParser.ResultByTakenID """
def getTFLTakenID(listResult) :
    TFLTakenID = []
    for item in listResult :
        if str(item[5]) != "" :
            TFLTakenID.append(item[1])
    return TFLTakenID


def switchToFrameMainMenu(myDriver): 
    #Loop to access SLB Domain.
    #If not in SLB Domain, eQ prompts a basic HTTP authentication (modal
    #dialog) that cannot be handled by Selenium. The user must enter his
    #LDAP credentials.
    machineInSlbDomain = False
    while not machineInSlbDomain:
        try:
            focusDefaultContent(myDriver)
            myDriver.switch_to_frame(myDriver.find_element_by_name("main_menu"))
            machineInSlbDomain = True            
        except:
            myDriver.get(myUrl)
            time.sleep(waitLogin)

""" Re-focus on the window before any mouse action. """
def focusActiveElement(myDriver):
    myDriver.switch_to_active_element()

def focusDefaultContent(myDriver):
    myDriver.switch_to_default_content()

""" cuts a string into smaller strings of fewer than 255 characters """
def split255(seqLong, maxIdLen):
    seqSplit = []
    while len(seqLong) > 255:
        for i in range(0 , maxIdLen):
            if seqLong[254 - i] ==',':
                seqSplit.append(seqLong[ : 254 - i ])
                seqLong = seqLong[ 255 - i : ]
                break
    seqSplit.append(seqLong)
    return seqSplit

""" gets content from a config file and returns it as a dict {  type: (date or serialNumbers),
                                                                content: (serialNumbersPrefixes if type : date or serialNumbers if type = serialNumbers)
                                            (if type = date)>>  date: date } """
def getInput(relativePath):
    JsonInput = open( relativePath, "r")
    buff = JsonInput.read()
    monInput = dict()
    config = json.loads(buff)
    monType = config['type']
    
    if monType == 'serialNumbers' :
        contenu = [sn for family in config['families'] for sn in family['serialNumbers']]
        contenu = ', '.join(contenu)
    elif monType == 'date' :
        contenu = ''
        monInput['date'] = config['date'].encode("utf-8")
        for family in config['families']:
            if family['serialNumbersPrefix']:
                contenu += family['serialNumbersPrefix'] + '%, '
        contenu = contenu[:-2]
    monInput['type'] = monType.encode("utf-8")
    monInput['contenu'] = contenu.encode("utf-8")
    JsonInput.close()
    return monInput

""" manages the browser to get the wanted Mats results page if input-type = serialNumbers """
def matsGoSN(browser, listMats):    
    myMatsListResult = []
    inputSN = 'serial_no'
    submit = 'sabutton'
    
    try :
        listMatsSplit = split255(listMats,maxIdLen)
    except :
        print '\nError : Unsplitable input. MaxIdLen variable in main should probably be increased.'
        browser.close()
        
    while listMatsSplit :    
        try :
            browser.get(myUrl)
        except :
            print '\nError : eQuality is unreachable.'
            browser.close()
        try :
            switchToFrameMainMenu(browser)

            """ finding the MatsQuery area"""
            area = browser.find_element_by_xpath("//area[contains(@alt, 'Query Performed Tests')]")
            """ clicking on it """
            area.click()
        except :
            '\nError : Problem during Mats Research while handling home page.'
            browser.close()

        try :        
            """ writing the list in the takenID input """
            browser.find_element_by_name(inputSN).send_keys(listMatsSplit.pop())

            """ finding the submit button """
            t = browser.find_element_by_name(submit)

            """clicking on it """
            focusActiveElement(browser)
            t.click()
            t.click() # Click twice in case the first click just re-focused the window.
            t.submit()
        except :
            print '\nError : Problem during Mats Research while handling search page.'
            browser.close()

        try :
            """ getting the result list of the datas we need from this MatsQueryResult page """
            myMatsparser = MatsParser()
            myMatsparser.feedEveryPage(browser)
            myMatsListResult += myMatsparser.getResultByTakenID()
        except :
            print '\nError : Problem during Mats Research while parsing the data.'
            browser.close()

    """ saving the results into Mats.csv """
    try :
        listToCsv( 'Mats.csv', myMatsListResult )
    except :
        print '\nError : problem during Mats Research while saving the results.'
        browser.close()

    return myMatsListResult

""" manages the browser to get the wanted Mats results page if input-type = date """
def matsGoDate(browser, date, listPrefixes): # we chose the "performed date" input, might need a change here if we'd rather choose "modified date"
    myMatsListResult = []
    inputPrefixes = 'serial_no'
    inputDateSelect = 'performed_date_Op'
    inputDate = 'performed_date'
    submit = 'sabutton'
    
    try :
        listPrefixesSplit = split255(listPrefixes, maxIdLen)
    except :
        print '\nError : Unsplitable input. MaxIdLen variable in main should probably be increased.'
        browser.close()

    while listPrefixesSplit :
        try :
            browser.get(myUrl)
        except :
            print '\nError : eQuality is unreachable.'
            browser.close()

        try :
            switchToFrameMainMenu(browser)
            """ finding the MatsQuery area"""
            area = browser.find_element_by_xpath("//area[contains(@alt, 'Query Performed Tests')]")
            """ clicking on it """
            area.click()
        except :
            print '\nError : Problem during Mats Research while handling home page.'
            browser.close()

        try :    
            """ writing the prefixes in the prefixes input """
            browser.find_element_by_name(inputPrefixes).send_keys(listPrefixesSplit.pop())                       
            
            """ writing the list in the Performed Date input """
            inputElement = browser.find_element_by_name(inputDateSelect)
            inputElement.click()

            selected = ''
            while selected != '>=' :
                for option in inputElement.find_elements_by_tag_name("option"):
                    if (option.get_attribute('selected')):
                        selected = option.get_attribute('value')
                    if option.get_attribute('value') == '>=': # indicating we want all tests performed after the specified date
                        option.click()
                        browser.find_element_by_name(inputDate).click()
                        

            """ writing the list in the date input """
            browser.find_element_by_name(inputDate).send_keys(date)
                        
            """ finding the submit button """
            t = browser.find_element_by_name(submit)

            """clicking on it """
            focusActiveElement(browser)
            t.click()
            t.click() # Click twice in case the first click just re-focused the window.
            t.submit()
        except :
            print '\nError : Problem during Mats Research while handling search page.'
            browser.close()

        try : 
            """ getting the result list of the datas we need from this MatsQueryResult page """
            myMatsparser = MatsParser()
            myMatsparser.feedEveryPage(browser)
            myMatsListResult += myMatsparser.getResultByTakenID()
        except :
            print '\nError : Problem during Mats Research while parsing the data.'
            browser.close()

    """ saving it into Mats.csv """
    try :
        listToCsv( 'Mats.csv', myMatsListResult )
    except :
        print '\nError : Problem during Mats Research while saving the results.'
        browser.close()

    return myMatsListResult

""" manages the browser to get the wanted TFL results page """
def TFLGo(browser, listTFL ,maxIdLen):
    myTFLListResult = []
    takenIDInput = 'test_taken_id'
    submit = 'sabutton'
    try :
        listTFLSplit = split255(listTFL,maxIdLen)
    except :
        print '\nError : Unsplitable input. MaxIdLen variable in main should probably be increased.'
        browser.close()

    while listTFLSplit :  
        try :
            browser.get(myUrl)
        except :
            print '\nError : eQuality is unreachable.'
            browser.close()

        try :
            switchToFrameMainMenu(browser)

            """ finding the TFLQuery image """
            img = browser.find_element_by_xpath("//img[contains(@alt, 'Test Failed')]")

            """ clicking on it """
            img.click()
        except :
            print '\nError : Problem during TFL Research while handling home page.'
            browser.close()

        try : 
            """ writing the list into the takenID input """
            browser.find_element_by_name(takenIDInput).send_keys(listTFLSplit.pop())

            """ finding the submit button """
            t = browser.find_element_by_name(submit)

            """ clicking on it """
            focusActiveElement(browser)
            t.click()
            t.click() # Click twice in case the first click just re-focused the window.
            t.submit()
        except :
            print '\nError : Problem during TFL Research while handling search page.'
            browser.close()

        try :
            """ getting the result list of the datas we need from this MatsQueryResult page """
            myTFLparser = TFLParser()
            myTFLparser.feedEveryPage(browser)
            myTFLListResult += myTFLparser.getResultByTakenID()        
        except :
            print '\nError : Problem during TFL Research while parsing the data.'
            browser.close()

    try :
        listToCsv( 'Relative_TFLs.csv', myTFLListResult )
    except :
        print '\nError : Problem during TFL Research while saving the results.'
        browser.close()

    return myTFLListResult



"""""""""""""""""""""""""""""""      MAIN     """""""""""""""""""""""""""""""""


waitLogin = 15 # sets the time the user will have to login 
maxIdLen = 15 #sets the expected maximum length of an ID for 255 spliting 

print '===      EXTRACTION STARTED      === \n ' 
#################  getting the input from the config file  #################
try :
    resultJson = getInput('configDate.json')                                    # SET PATH TO CONFIG FILE HERE !
    print '=== Succesful config file import ==='
except :
    print 'Error : Unable to import config.'
############################################################################


#################  starting up a firefox browser instance  #################
myUrl = "file:///" + os.path.dirname(os.path.abspath(__file__)) + "/home.htm"   # SET eQUALITY HOME PAGE URL HERE !
#myUrl = "http://www.equality-eur.slb.com"
browser = webdriver.Firefox()
browser.maximize_window()
browser.implicitly_wait(5)
############################################################################


##########  Parsing the Mats and deducting the TFL to look for  ############
if resultJson['type'] == 'serialNumbers':
    myMatsListResult = matsGoSN(browser , resultJson['contenu'])
elif resultJson['type'] == 'date':
    myMatsListResult = matsGoDate(browser , resultJson['date'], resultJson['contenu'])
""" Either way, results are saved in 'Mats.csv' """
print '===    Succesful Mats parsing    ==='
############################################################################
    
############################  Parsing the TFLs   ###########################
listTFL = str(getTFLTakenID(myMatsListResult)).replace(" ', '", ",").replace("'","")[1:-2]
myTFLListResult = TFLGo(browser,listTFL,maxIdLen)
""" results are saved in 'Relative_TFLs.csv' """
print '===    Succesful TFLs parsing    ==='
############################################################################

browser.close()

print  ' \n===     SUCCESFUL EXTRACTION     ==='


